{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///./data/disaster_response.db')\n",
    "df = pd.read_sql_table('messages', engine)\n",
    "\n",
    "labels = [col for col in df.columns if col not in ['id', 'message', 'original', 'genre', 'related']]\n",
    "\n",
    "X = df['message'].values\n",
    "y = df[labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization function\n",
    "def tokenize(text):\n",
    "    clean_text = text.lower() # convert all chars to lower case\n",
    "    clean_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", clean_text) # remove non alpha-numeric characters\n",
    "    clean_text = re.sub(' +', ' ', clean_text) # remove duplicate spaces\n",
    "    \n",
    "    # tokenize text\n",
    "    words = word_tokenize(clean_text)\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # reduce words to their stems\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = [stemmer.stem(w) for w in words]\n",
    "    \n",
    "    # reduce words to root form\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(w) for w in stemmed]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(random_state=42, n_jobs=-1)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x000001F66638D670>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(n_jobs=-1,\n",
       "                                                                        random_state=42)))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# fit model\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.83      0.72      0.77       733\n",
      "                 offer       0.00      0.00      0.00         1\n",
      "           aid_related       0.82      0.75      0.78       801\n",
      "          medical_help       0.71      0.11      0.19       111\n",
      "      medical_products       0.83      0.07      0.13        71\n",
      "     search_and_rescue       1.00      0.02      0.04        46\n",
      "              security       0.00      0.00      0.00        24\n",
      "              military       0.00      0.00      0.00        12\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.93      0.79      0.86       153\n",
      "                  food       0.92      0.82      0.87       312\n",
      "               shelter       0.87      0.46      0.60       211\n",
      "              clothing       0.00      0.00      0.00        15\n",
      "                 money       0.00      0.00      0.00        22\n",
      "        missing_people       0.00      0.00      0.00        16\n",
      "              refugees       0.00      0.00      0.00        29\n",
      "                 death       0.60      0.07      0.12        45\n",
      "             other_aid       0.67      0.07      0.13       304\n",
      "infrastructure_related       0.00      0.00      0.00        60\n",
      "             transport       0.00      0.00      0.00        33\n",
      "             buildings       0.67      0.25      0.37        71\n",
      "           electricity       0.00      0.00      0.00        13\n",
      "                 tools       0.00      0.00      0.00         3\n",
      "             hospitals       0.00      0.00      0.00        12\n",
      "                 shops       0.00      0.00      0.00         9\n",
      "           aid_centers       0.00      0.00      0.00        14\n",
      "  other_infrastructure       0.00      0.00      0.00        26\n",
      "       weather_related       0.85      0.61      0.71       268\n",
      "                floods       0.84      0.31      0.46        51\n",
      "                 storm       0.75      0.20      0.31        46\n",
      "                  fire       0.00      0.00      0.00         6\n",
      "            earthquake       0.88      0.78      0.83       138\n",
      "                  cold       0.00      0.00      0.00        12\n",
      "         other_weather       1.00      0.02      0.05        41\n",
      "         direct_report       0.78      0.69      0.73       689\n",
      "\n",
      "             micro avg       0.83      0.55      0.66      4398\n",
      "             macro avg       0.40      0.19      0.23      4398\n",
      "          weighted avg       0.76      0.55      0.61      4398\n",
      "           samples avg       0.35      0.26      0.28      4398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# predict on test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# print model results\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
