{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3 as sql\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "conn = create_engine('sqlite:///C:/Users/gradi/Documents/projects/machine_learning/disaster_response_model/data/DisasterResponse.db')\n",
    "df = pd.read_sql_table('messages', conn)\n",
    "\n",
    "X = df['message'].values\n",
    "y = df.iloc[:, 4:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization function\n",
    "def tokenize(text):\n",
    "    clean_text = text.lower() # convert all chars to lower case\n",
    "    clean_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", clean_text) # remove non alpha-numeric characters\n",
    "    clean_text = re.sub(' +', ' ', clean_text) # remove duplicate spaces\n",
    "    \n",
    "    # tokenize text\n",
    "    words = word_tokenize(clean_text)\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # reduce words to their stems\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = [stemmer.stem(w) for w in words]\n",
    "    \n",
    "    # reduce words to root form\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_tokens = [lemmatizer.lemmatize(w) for w in stemmed]\n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer(smooth_idf=False)),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    # define parameters\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(1, 1), (1, 2), (2, 3)],\n",
    "        'clf__max_depth': [None, 4, 8],\n",
    "        'clf__n_estimators': [50, 100, 200]\n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model and fit\n",
    "model = build_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print model results\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionMarkCount(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # code here to transform data\n",
    "        X_qcount = pd.Series(X).apply(lambda x: x.count('?'))\n",
    "        \n",
    "        return pd.DataFrame(X_qcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExclamationPointCount(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # code here to transform data\n",
    "        X_expointcount = pd.Series(X).apply(lambda x: x.count('!'))\n",
    "        \n",
    "        return pd.DataFrame(X_expointcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapitalCount(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # code here to transform data\n",
    "        X_capitalcount = pd.Series(X).apply(lambda text: sum(1 for c in text if c.isupper()))\n",
    "        \n",
    "        return pd.DataFrame(X_capitalcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordCount(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # code here to transform data\n",
    "        X_wordcount = pd.Series(X).apply(lambda x: len(x.split()))\n",
    "        \n",
    "        return pd.DataFrame(X_wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_v2():\n",
    "    # build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('textpipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1,2))),\n",
    "                ('tfidf', TfidfTransformer(smooth_idf=False)),\n",
    "            ])),\n",
    "            ('qmark_count', QuestionMarkCount()),\n",
    "            ('expoint_count', ExclamationPointCount()),\n",
    "            ('capital_count', CapitalCount()),\n",
    "            ('word_count', WordCount())\n",
    "        ])),\n",
    "        ('clf', RandomForestClassifier(n_estimators=200))\n",
    "    ])\n",
    "    \n",
    "    # define parameters\n",
    "    parameters = {\n",
    "        'features__transformer_weights': (\n",
    "            {'text_pipeline': 0.6, 'word_count': 0.1, 'qmark_count': 0.1, 'expoint_count': 0.1, 'capital_count': 0.1},\n",
    "            {'text_pipeline': 0.8, 'word_count': 0.05, 'qmark_count': 0.05, 'expoint_count': 0.05, 'capital_count': 0.05},\n",
    "            {'text_pipeline': 0.95, 'word_count': 0.0125, 'qmark_count': 0.0125, 'expoint_count': 0.0125, 'capital_count': 0.0125}\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('textpipeline',\n",
       "                                                                        Pipeline(steps=[('vect',\n",
       "                                                                                         CountVectorizer(ngram_range=(1,\n",
       "                                                                                                                      2),\n",
       "                                                                                                         tokenizer=<function tokenize at 0x000001F66638D670>)),\n",
       "                                                                                        ('tfidf',\n",
       "                                                                                         TfidfTransformer(smooth_idf=False))])),\n",
       "                                                                       ('qmark_count',\n",
       "                                                                        QuestionMarkCount()),\n",
       "                                                                       ('expoint_count',\n",
       "                                                                        ExclamationPointCount()),\n",
       "                                                                       ('capital_count',...\n",
       "             param_grid={'features__transformer_weights': ({'capital_count': 0.1,\n",
       "                                                            'expoint_count': 0.1,\n",
       "                                                            'qmark_count': 0.1,\n",
       "                                                            'text_pipeline': 0.6,\n",
       "                                                            'word_count': 0.1},\n",
       "                                                           {'capital_count': 0.05,\n",
       "                                                            'expoint_count': 0.05,\n",
       "                                                            'qmark_count': 0.05,\n",
       "                                                            'text_pipeline': 0.8,\n",
       "                                                            'word_count': 0.05},\n",
       "                                                           {'capital_count': 0.0125,\n",
       "                                                            'expoint_count': 0.0125,\n",
       "                                                            'qmark_count': 0.0125,\n",
       "                                                            'text_pipeline': 0.95,\n",
       "                                                            'word_count': 0.0125})})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model and fit\n",
    "print('Building model...')\n",
    "model_v2 = build_model_v2()\n",
    "\n",
    "print('Fitting model...')\n",
    "model_v2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.87      0.67      0.75       733\n",
      "                 offer       0.00      0.00      0.00         1\n",
      "           aid_related       0.86      0.65      0.74       801\n",
      "          medical_help       0.33      0.01      0.02       111\n",
      "      medical_products       0.00      0.00      0.00        71\n",
      "     search_and_rescue       0.00      0.00      0.00        46\n",
      "              security       0.00      0.00      0.00        24\n",
      "              military       0.00      0.00      0.00        12\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.96      0.62      0.75       153\n",
      "                  food       0.94      0.68      0.79       312\n",
      "               shelter       0.87      0.33      0.48       211\n",
      "              clothing       0.00      0.00      0.00        15\n",
      "                 money       0.00      0.00      0.00        22\n",
      "        missing_people       0.00      0.00      0.00        16\n",
      "              refugees       0.00      0.00      0.00        29\n",
      "                 death       0.75      0.07      0.12        45\n",
      "             other_aid       0.60      0.05      0.09       304\n",
      "infrastructure_related       0.50      0.02      0.03        60\n",
      "             transport       0.00      0.00      0.00        33\n",
      "             buildings       0.57      0.11      0.19        71\n",
      "           electricity       0.00      0.00      0.00        13\n",
      "                 tools       0.00      0.00      0.00         3\n",
      "             hospitals       0.00      0.00      0.00        12\n",
      "                 shops       0.00      0.00      0.00         9\n",
      "           aid_centers       0.00      0.00      0.00        14\n",
      "  other_infrastructure       0.00      0.00      0.00        26\n",
      "       weather_related       0.88      0.31      0.46       268\n",
      "                floods       0.86      0.12      0.21        51\n",
      "                 storm       0.25      0.02      0.04        46\n",
      "                  fire       0.00      0.00      0.00         6\n",
      "            earthquake       0.86      0.48      0.61       138\n",
      "                  cold       0.50      0.08      0.14        12\n",
      "         other_weather       0.00      0.00      0.00        41\n",
      "         direct_report       0.82      0.62      0.71       689\n",
      "\n",
      "             micro avg       0.86      0.46      0.59      4398\n",
      "             macro avg       0.33      0.14      0.18      4398\n",
      "          weighted avg       0.74      0.46      0.54      4398\n",
      "           samples avg       0.29      0.21      0.23      4398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Validating model...')\n",
    "# predict on test data\n",
    "y_pred = model_v2.predict(X_test)\n",
    "\n",
    "# print model results\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features__transformer_weights': {'text_pipeline': 0.8,\n",
       "  'word_count': 0.05,\n",
       "  'qmark_count': 0.05,\n",
       "  'expoint_count': 0.05,\n",
       "  'capital_count': 0.05}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying with an AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_v3():\n",
    "    # build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('textpipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1,2))),\n",
    "                ('tfidf', TfidfTransformer(smooth_idf=False)),\n",
    "            ])),\n",
    "            ('qmark_count', QuestionMarkCount()),\n",
    "            ('expoint_count', ExclamationPointCount()),\n",
    "            ('capital_count', CapitalCount()),\n",
    "            ('word_count', WordCount())\n",
    "        ])),\n",
    "        ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "    ])\n",
    "    \n",
    "    # define parameters\n",
    "    parameters = {\n",
    "        'clf__estimator__learning_rate': [0.8, 1.0, 1.4],\n",
    "        'clf__estimator__n_estimators': [50, 100, 200],\n",
    "        'features__transformer_weights': [{'text_pipeline': 0.8, 'word_count': 0.05, 'qmark_count': 0.05, 'expoint_count': 0.05, 'capital_count': 0.05}]\n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model v3...\n",
      "Fitting model v3...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('textpipeline',\n",
       "                                                                        Pipeline(steps=[('vect',\n",
       "                                                                                         CountVectorizer(ngram_range=(1,\n",
       "                                                                                                                      2),\n",
       "                                                                                                         tokenizer=<function tokenize at 0x000001F66638D670>)),\n",
       "                                                                                        ('tfidf',\n",
       "                                                                                         TfidfTransformer(smooth_idf=False))])),\n",
       "                                                                       ('qmark_count',\n",
       "                                                                        QuestionMarkCount()),\n",
       "                                                                       ('expoint_count',\n",
       "                                                                        ExclamationPointCount()),\n",
       "                                                                       ('capital_count',\n",
       "                                                                        CapitalCount()),\n",
       "                                                                       ('word_count',\n",
       "                                                                        WordCount())])),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier()))]),\n",
       "             param_grid={'clf__estimator__learning_rate': [0.8, 1.0, 1.4],\n",
       "                         'clf__estimator__n_estimators': [50, 100, 200],\n",
       "                         'features__transformer_weights': [{'capital_count': 0.05,\n",
       "                                                            'expoint_count': 0.05,\n",
       "                                                            'qmark_count': 0.05,\n",
       "                                                            'text_pipeline': 0.8,\n",
       "                                                            'word_count': 0.05}]})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model and fit\n",
    "print('Building model v3...')\n",
    "model_v3 = build_model_v3()\n",
    "\n",
    "print('Fitting model v3...')\n",
    "model_v3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating model...\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.83      0.67      0.74       733\n",
      "                 offer       0.00      0.00      0.00         1\n",
      "           aid_related       0.82      0.69      0.75       801\n",
      "          medical_help       0.72      0.26      0.38       111\n",
      "      medical_products       0.75      0.42      0.54        71\n",
      "     search_and_rescue       0.29      0.04      0.08        46\n",
      "              security       0.00      0.00      0.00        24\n",
      "              military       0.50      0.17      0.25        12\n",
      "           child_alone       0.00      0.00      0.00         0\n",
      "                 water       0.92      0.88      0.90       153\n",
      "                  food       0.90      0.87      0.88       312\n",
      "               shelter       0.78      0.69      0.73       211\n",
      "              clothing       0.38      0.20      0.26        15\n",
      "                 money       0.29      0.18      0.22        22\n",
      "        missing_people       0.12      0.06      0.08        16\n",
      "              refugees       0.38      0.10      0.16        29\n",
      "                 death       0.43      0.33      0.38        45\n",
      "             other_aid       0.57      0.23      0.33       304\n",
      "infrastructure_related       0.36      0.08      0.14        60\n",
      "             transport       0.00      0.00      0.00        33\n",
      "             buildings       0.63      0.52      0.57        71\n",
      "           electricity       0.40      0.15      0.22        13\n",
      "                 tools       0.00      0.00      0.00         3\n",
      "             hospitals       0.33      0.17      0.22        12\n",
      "                 shops       0.67      0.22      0.33         9\n",
      "           aid_centers       0.12      0.07      0.09        14\n",
      "  other_infrastructure       0.00      0.00      0.00        26\n",
      "       weather_related       0.84      0.61      0.71       268\n",
      "                floods       0.84      0.31      0.46        51\n",
      "                 storm       0.62      0.39      0.48        46\n",
      "                  fire       0.25      0.17      0.20         6\n",
      "            earthquake       0.85      0.80      0.82       138\n",
      "                  cold       0.14      0.08      0.11        12\n",
      "         other_weather       0.42      0.12      0.19        41\n",
      "         direct_report       0.76      0.64      0.70       689\n",
      "\n",
      "             micro avg       0.78      0.58      0.67      4398\n",
      "             macro avg       0.45      0.29      0.34      4398\n",
      "          weighted avg       0.74      0.58      0.64      4398\n",
      "           samples avg       0.33      0.27      0.28      4398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Validating model...')\n",
    "# predict on test data\n",
    "y_pred = model_v3.predict(X_test)\n",
    "\n",
    "# print model results\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__learning_rate': 0.8,\n",
       " 'clf__estimator__n_estimators': 50,\n",
       " 'features__transformer_weights': {'text_pipeline': 0.8,\n",
       "  'word_count': 0.05,\n",
       "  'qmark_count': 0.05,\n",
       "  'expoint_count': 0.05,\n",
       "  'capital_count': 0.05}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best model parameters...')\n",
    "model_v3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_v4():\n",
    "    # build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('textpipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1,2))),\n",
    "                ('tfidf', TfidfTransformer(smooth_idf=False)),\n",
    "            ])),\n",
    "            ('qmark_count', QuestionMarkCount()),\n",
    "            ('expoint_count', ExclamationPointCount()),\n",
    "            ('capital_count', CapitalCount()),\n",
    "            ('word_count', WordCount())\n",
    "        ])),\n",
    "        ('clf', MultiOutputClassifier(GradientBoostingClassifier()))\n",
    "    ])\n",
    "    \n",
    "    # define parameters\n",
    "    parameters = {\n",
    "        'clf__estimator__max_depth': [3, 5, 8],\n",
    "        'clf__estimator__n_estimators': [50, 100, 200],\n",
    "        'clf__estimator__learning_rate': [0.08, 0.1, 0.2],\n",
    "        'features__transformer_weights': [{'text_pipeline': 0.8, 'word_count': 0.05, 'qmark_count': 0.05, 'expoint_count': 0.05, 'capital_count': 0.05}]\n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model v4...\n",
      "Fitting model v4...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('features',\n",
       "                                        FeatureUnion(transformer_list=[('textpipeline',\n",
       "                                                                        Pipeline(steps=[('vect',\n",
       "                                                                                         CountVectorizer(ngram_range=(1,\n",
       "                                                                                                                      2),\n",
       "                                                                                                         tokenizer=<function tokenize at 0x000002019B0B7E50>)),\n",
       "                                                                                        ('tfidf',\n",
       "                                                                                         TfidfTransformer(smooth_idf=False))])),\n",
       "                                                                       ('qmark_count',\n",
       "                                                                        QuestionMarkCount()),\n",
       "                                                                       ('expoint_count',\n",
       "                                                                        ExclamationPointCount()),\n",
       "                                                                       ('capital_count',...\n",
       "                                                                        WordCount())])),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=GradientBoostingClassifier()))]),\n",
       "             param_grid={'clf__estimator__learning_rate': [0.08, 0.1, 0.2],\n",
       "                         'clf__estimator__max_depth': [3, 5, 8],\n",
       "                         'clf__estimator__n_estimators': [50, 100, 200],\n",
       "                         'features__transformer_weights': [{'capital_count': 0.05,\n",
       "                                                            'expoint_count': 0.05,\n",
       "                                                            'qmark_count': 0.05,\n",
       "                                                            'text_pipeline': 0.8,\n",
       "                                                            'word_count': 0.05}]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model and fit\n",
    "print('Building model v4...')\n",
    "model_v4 = build_model_v4()\n",
    "\n",
    "print('Fitting model v4...')\n",
    "model_v4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__learning_rate': 0.08,\n",
       " 'clf__estimator__max_depth': 5,\n",
       " 'clf__estimator__n_estimators': 50,\n",
       " 'features__transformer_weights': {'text_pipeline': 0.8,\n",
       "  'word_count': 0.05,\n",
       "  'qmark_count': 0.05,\n",
       "  'expoint_count': 0.05,\n",
       "  'capital_count': 0.05}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Best model v4 parameters...')\n",
    "model_v4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating model v4...\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "               request       0.83      0.67      0.74       733\n",
      "                 offer       0.00      0.00      0.00         1\n",
      "           aid_related       0.84      0.68      0.76       801\n",
      "          medical_help       0.74      0.25      0.38       111\n",
      "      medical_products       0.68      0.42      0.52        71\n",
      "     search_and_rescue       0.19      0.07      0.10        46\n",
      "              security       0.08      0.08      0.08        24\n",
      "              military       0.00      0.00      0.00        12\n",
      "                 water       0.89      0.91      0.90       153\n",
      "                  food       0.88      0.92      0.90       312\n",
      "               shelter       0.82      0.67      0.74       211\n",
      "              clothing       0.82      0.60      0.69        15\n",
      "                 money       0.30      0.32      0.31        22\n",
      "        missing_people       0.13      0.12      0.13        16\n",
      "              refugees       0.12      0.07      0.09        29\n",
      "                 death       0.41      0.36      0.38        45\n",
      "             other_aid       0.66      0.25      0.36       304\n",
      "infrastructure_related       0.14      0.02      0.03        60\n",
      "             transport       0.00      0.00      0.00        33\n",
      "             buildings       0.59      0.59      0.59        71\n",
      "           electricity       0.11      0.08      0.09        13\n",
      "                 tools       0.00      0.00      0.00         3\n",
      "             hospitals       0.20      0.17      0.18        12\n",
      "                 shops       0.50      0.11      0.18         9\n",
      "           aid_centers       0.09      0.07      0.08        14\n",
      "  other_infrastructure       0.14      0.12      0.13        26\n",
      "       weather_related       0.87      0.61      0.72       268\n",
      "                floods       0.64      0.35      0.46        51\n",
      "                 storm       0.65      0.48      0.55        46\n",
      "                  fire       0.00      0.00      0.00         6\n",
      "            earthquake       0.81      0.81      0.81       138\n",
      "                  cold       0.33      0.08      0.13        12\n",
      "         other_weather       0.19      0.12      0.15        41\n",
      "         direct_report       0.79      0.62      0.70       689\n",
      "\n",
      "             micro avg       0.77      0.59      0.67      4398\n",
      "             macro avg       0.42      0.31      0.35      4398\n",
      "          weighted avg       0.75      0.59      0.65      4398\n",
      "           samples avg       0.33      0.27      0.28      4398\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Validating model v4...')\n",
    "# predict on test data\n",
    "y_pred = model_v4.predict(X_test)\n",
    "\n",
    "# print model results\n",
    "print(classification_report(y_test, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure Reported: weighted averages\n",
    "\n",
    "| Model | Fitting | Precision | Recall | F1 Precision |\n",
    "| :---- | :---- | :-------: | :----: | :----------: |\n",
    "| Random Forrest Classifier | single fit | 0.76 | 0.55 | 0.61 |\n",
    "| Random Forrest Classifier | grid search cross-validation | 0.74 | 0.46 | 0.55 |\n",
    "| Random Forrest Classifier | previous + 4 extra features | 0.74 | 0.46 | 0.54 |\n",
    "| AdaBoost Classifier | as previous | 0.74 | 0.58 | 0.64 |\n",
    "| Gradient Boosting Classifier | as previous | 0.75 | 0.59 | 0.65 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_final():\n",
    "    # build pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('textpipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize, ngram_range=(1,2))),\n",
    "                ('tfidf', TfidfTransformer(smooth_idf=False)),\n",
    "            ])),\n",
    "            ('qmark_count', QuestionMarkCount()),\n",
    "            ('expoint_count', ExclamationPointCount()),\n",
    "            ('capital_count', CapitalCount()),\n",
    "            ('word_count', WordCount())\n",
    "        ])),\n",
    "        ('clf', MultiOutputClassifier(GradientBoostingClassifier(max_depth=5, n_estimators=50, learning_rate=0.08)))\n",
    "    ])\n",
    "    \n",
    "    # define parameters\n",
    "    parameters = {\n",
    "        'features__transformer_weights': [{'text_pipeline': 0.8, 'word_count': 0.05, 'qmark_count': 0.05, 'expoint_count': 0.05, 'capital_count': 0.05}]\n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "    \n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building finsl model...\n",
      "Fitting final model...\n",
      "Saving final model to disk...\n"
     ]
    }
   ],
   "source": [
    "# instantiate model and fit\n",
    "print('Building finsl model...')\n",
    "final_model = build_model_final()\n",
    "\n",
    "print('Fitting final model...')\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# save model to disk\n",
    "print('Saving final model to disk...')\n",
    "filename = 'disaster_response_model.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\gradi\\\\Documents\\\\projects\\\\machine_learning\\\\disaster_response'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "request (3607) \n",
      "----\n",
      "2683:\ti m still waiting for your help. .. i'm starving, please bring me food\n",
      "4686:\tTHERE IS A MISTAKE IN THE FOOD DISTRIBUTION,SOME PEOPLE GIVE CARDS TO ONLY TO PEOPLE THEY KNOW..!! I HAVE TO BEG OTHER PEOPLE SO THEY CAN EAT,IT'S NOT FAIR. \n",
      "2618:\thello we are in ile a vache. in the trou milieu area. we have 13 people 2 babys among them\n",
      "879:\tSORRY I GOT NOTHING TO HEAR NO POWER NO RADIO ONLY MY CELLPHONE PLEASE WRITE ME OR CALL ME I NEED YOUR HELP\n",
      "3928:\tOh my Gosh, we are dying with hunger and thirst in LIlavois 47. \n",
      "\n",
      "\n",
      "\n",
      "offer (10) \n",
      "----\n",
      "255:\tHow can we help the victims at Les Cayes?\n",
      "3573:\ti want to give blood where do I go \n",
      "\n",
      "\n",
      "\n",
      "aid_related (3931) \n",
      "----\n",
      "4759:\tCarrefour Feuilles needs food, drinking water and tents. \n",
      "2465:\tWe did not find any help in La Grenade, we still have people under the Rubble. We have no food and water.\n",
      "570:\tIN MY CITY. WE WANTED YOUR HELP PLEASE WE NEED OF THE FOODS, WATERS. WEARS. HOUSES. BEACAUSE OURS HOUSES IS DESTROYED BY THE CATASTROPH. We are in the stre\n",
      "114:\tI am in Petion Ville, in b. .. incomprehensible, we have no water, there is nothing, there is no money. What is being given in Petion Ville and where?\n",
      "2256:\tCit Militaire, we need water / food\n",
      "\n",
      "\n",
      "\n",
      "medical_help (574) \n",
      "----\n",
      "5058:\tHow many fatality missing do we have in Port-au-Prince? \n",
      "4902:\tPeole that are living in La Montay especially in Lespinas need medical aid. \n",
      "876:\tThe house is broken. There are 5 people who have been injured. We need urgent assistance. Please call the number for location.\n",
      "3866:\t.. psychologically I am really sick because my older brother died in front of me. He was the only person working to support the family financially. We need psychologist's help, please. \n",
      "5227:\tThere are a lot of diseases from infection in haiti -- what should we do? \n",
      "\n",
      "\n",
      "\n",
      "medical_products (342) \n",
      "----\n",
      "2912:\tNO location : we need food, water, tents, diapers, cookies, sugar, please help us.\n",
      "7557:\tMy dady was dead long time ago, now I lose my mom and three of my brothers during the earthquake, every time I think about that, I can't support my head (headache), what can I do in that situation, it's very important. \n",
      "10030:\tDadu still needs food, medicines, cloths, metresses, blankets\n",
      "2400:\tNeed medicine and many tents. At Telandieu and Leonord. Thank you in advance.\n",
      "433:\tthey need help of every king, food, water, health services at Thomassin 32, 12 19 km east of Port-au-Prince. There are about 300 people\n",
      "\n",
      "\n",
      "\n",
      "search_and_rescue (206) \n",
      "----\n",
      "934:\tHello, we are in the Petionville area we need tents, food and water\n",
      "593:\twe make an inventory. There are a lot of destryed houses. A lot of injured people. Lot of deads. It is a catastrophy. Please make an effort for these people. Our address is Route des Freres in Perrier. .. NEED SERIOUS HELP\n",
      "10043:\tEVERY THING IS DAMAGE IN MY CITY TO FLOOD.CITY NAME DERA ALLAH YAR TEHSIL JHAT PAT DISTRICT JAFARABAD BALOCHISTAN.\n",
      "4509:\tGood evening, we live in Bon Repos in the area of Rose amber (?) at the entrance of route .. Since January 12th, no one came to see us. Our house is destroyed, we are in the street and we are asking for aid. \n",
      "7099:\tI AM SO HUNGRY ,I PRAY,BUT I CANNOT GET HELP CALL ME \n",
      "\n",
      "\n",
      "\n",
      "security (129) \n",
      "----\n",
      "5216:\tHow could you forget me, what will you do for me. I am suffering for three reasons, the first is food, the second is work, the third is sleep. I can't not suffer because I .. \n",
      "2321:\tThere are people under the Coeur Unis ( i'm guessing this is a church? ). And also, the hunger is killing me. Yesterday they pushed me so I did not recieve food. Fontamara 27. We need security a there are too many fights. \n",
      "936:\tHelp we need help we need, food, water and security, SOS they are going to kill us\n",
      "9549:\tthere is a expert will look-at the cracking house's after this earhquaque?i'm living at carade areatabarree i don't see them yet .i would like that,their visit my area.please \n",
      "78:\tWe would like to receive some help in the Section Communale. There is a lot of violence.\n",
      "\n",
      "\n",
      "\n",
      "military (44) \n",
      "----\n",
      "936:\tHelp we need help we need, food, water and security, SOS they are going to kill us\n",
      "3323:\tI thought it was possible help would come from the forreigners here. Leogane, route .. \n",
      "3041:\tno police officer ever there was only one since earthquake \n",
      "6772:\tI'm on the ground,I'm not inside of the house please help me quickly. \n",
      "4573:\tThere is a group of young men with machetes that are causing trouble in the Abri area of Site Militaire. We need a police presence here, please. \n",
      "\n",
      "\n",
      "\n",
      "water (789) \n",
      "----\n",
      "5230:\tI live in Marechal in the Gressier Commune. We need a tent, potable water, food. \n",
      "5075:\tWE ARE RESPOSIBLE OF THEIR HEALTH WE NEED VACCIN ,DRINK WATER, NO WE DONT HAVE ANY IN FONTAMA \n",
      "3859:\tMy house was destroyed and my father and my child died. I hear there are foreigners giving aid in the country, but i cannot find even a little water. My friends are supporting me. \n",
      "5388:\tIn Delmas 33, Rue Charbonnire prolonge. We need water and tent. \n",
      "346:\tWe're asking you please to bring everything that's possible. Food, clothse, water, money to save those people's lives. Where we are people died, houses fell\n",
      "\n",
      "\n",
      "\n",
      "food (1520) \n",
      "----\n",
      "5607:\ti would like to know where food and water are being distributed in carrefour and other areas \n",
      "1189:\tThere is so much hunger that if a person is eating a little something, somebody else takes it and runs away. As for water, tell them to come in the area every other day with treatment.\n",
      "4086:\tWHERE CAN I FIND FOOD ? I AM A SURVIVOR \n",
      "4745:\tWE ARE IN DELMAS 33 IN PREDAYE WE NEED FOOD TENTS CARE FOR ALL \n",
      "2705:\tI don't have food. Please send us some food. I live signo across Hospital Cardinal Leger.\n",
      "\n",
      "\n",
      "\n",
      "shelter (1088) \n",
      "----\n",
      "2672:\twe are in petit goave at liberte avenue. we have no house, no shelter, no water, no food. .. please help\n",
      "9893:\tIn our village Kachipul, flood affected very drastically. The flood destroys our crops, our houses and all belongings. The Govt. have not yet taken any steps to help us.\n",
      "6344:\tIf there is somewhere I can find a tent please let me know its very hard to be in the rain at 2:00 AM its very hard \n",
      "9956:\tin sukkur there is desperate need of tents, clothes and medicines, even a strong need of powder milk\n",
      "6987:\tWe need of helps as : food, water, tent, toilet of any quality and others. We are locate at the Street of the mines. \n",
      "\n",
      "\n",
      "\n",
      "clothing (100) \n",
      "----\n",
      "920:\tWe have no food left. We're looking for some help with food. We don't have clothing issues nor water but we do not have any food left. ( incomplete )\n",
      "2593:\tHello we are OSCB social organisation in petionville road #28 we need shelter, we need everything possible \n",
      "6133:\tWe are in need of assistance. we are abandonned here in petionville between Dirgue Road and the Health center. \n",
      "688:\tI need food and clothes, I am in Lasile.\n",
      "1117:\tThings aren't good at all we as you to send something B?l?s riy?l Charles no 17, we need tents, food and medicine \n",
      "\n",
      "\n",
      "\n",
      "money (125) \n",
      "----\n",
      "2255:\tI have many problems. I have nothing to eat. please, please put some money on my card so i can call someone. please, thanks in advance.\n",
      "3323:\tI thought it was possible help would come from the forreigners here. Leogane, route .. \n",
      "2532:\tGood evening, this is the commune of Thomazeau, the first section of Trou Caiman. Things are not good at all. a little can of rice is 50, see what you can do for us. Au Revoir\n",
      "3379:\tI am not sick thanks God. However I am in dire need of food in order to survive \n",
      "3039:\tPlease help me with the earthquake victims,they left P-au-P and come to countryside,I helped them with the little money that I have. \n",
      "\n",
      "\n",
      "\n",
      "missing_people (83) \n",
      "----\n",
      "2353:\tI cant contact my family since the devastation in Port-au-prince because my account is expired, i cant use a card, please help me\n",
      "834:\tThe authorities from Gressier hasnt done anything yet until this day. They only decided to have a meeting earlier at 2 pm, there are 6 People under the Rubbles. .. ( Msg lost )\n",
      "862:\tI am found. I'm in Cap Haitian. My house in port-au-prince is destroyed\n",
      "1533:\twhich radio station should I listen to to find out information about someone who went to get medical care in Saint-Domingue?\n",
      "8530:\thi 4636 did you give the news for tonight on an eventuel earthquake I heard a lot persons say that, I would want that you gave me more precision \n",
      "\n",
      "\n",
      "\n",
      "refugees (167) \n",
      "----\n",
      "913:\tMy friends, we are asking for water and food.\n",
      "8303:\tUnited nation see what you can do for us because we don't find anything,we have some people sick, here what we need: medicine, covers, our house is broke down. Claude felix ask that. \n",
      "3529:\tHi, I am one of the victims, I am asking the people in charge to send help to mondestin thimothe, I had a business and it's destroyed. \n",
      "8530:\thi 4636 did you give the news for tonight on an eventuel earthquake I heard a lot persons say that, I would want that you gave me more precision \n",
      "2430:\t. ..  3106 childrens, 2353 childrens with one parents, 206 orphans, 257 young, more than 500 families, 1189 adults, 152 elderly persons, 4000 refugees. .. . .. \n",
      "\n",
      "\n",
      "\n",
      "death (250) \n",
      "----\n",
      "7468:\tCondolences to all the nations whose soldier died in this catastrophe in Haiti on January 12. \n",
      "48:\tAm listening to radio in Jacmel. Need help to remove dead bodies at Colege la Trinite-universite, the bodies are the professors and students\n",
      "646:\tPlease, I am suffering. give me a cahnce to save a life. please call this number so i can be involved. thak you four comprehension\n",
      "3888:\tWe are starving. We possess (have) knowledge, we can not find work. What to do? \n",
      "795:\thello. please, i would like to join my family in the US\n",
      "\n",
      "\n",
      "\n",
      "other_aid (1459) \n",
      "----\n",
      "1892:\tI'm a victim in Casale. Want to know when there will be more earthquake. Thanks.\n",
      "6314:\tOrganizasyon CADEL asks to help them to save 309 families, 1600 persons in Leogane montay palmistaven. Thaks. \n",
      "3673:\tIs the the hospital in Delmas that is working? \n",
      "3766:\tI am a victim of the earthquake. My house is destroyed and I am now in Les Cayes with 2 young children and I don't have anything \n",
      "5657:\tWe, at Fougy before the GRIZ Rivera in the new road, are in need of umbrella, food and lines \n",
      "\n",
      "\n",
      "\n",
      "infrastructure_related (313) \n",
      "----\n",
      "9271:\tGood evening, Haiti has many problems, but they are those of the Haitians tou nan manch. That UNICEF and other ONG which made gifts at the public schools make inventories, because the children n' do not have where to sit down. \n",
      "2459:\tGood morning governemnt of this country. i am totally sorry becuase of a disaster ina country. ther eis a lot of damage in a city of p . .. \n",
      "5471:\tWe are in Bon Repos. We ask for tents because if the rain keeps falling we will have damage. If you are ready this message, have pity on us. God will bless you. \n",
      "2668:\tcould you give help by giving some portable toilet that would really help because our house and toilet is crushed\n",
      "7896:\tthe information we have to know about:Cyclone,health,education \n",
      "\n",
      "\n",
      "\n",
      "transport (192) \n",
      "----\n",
      "3327:\tThe people of ? need roads, electricity, medicine because there's an epidemic attacking them \n",
      "732:\tIt is cold in Cuba this morning. It could reach Haiti tomorrow. Some showers are predicted for our area tonight.\n",
      "138:\tCan people enter their houses? When will we have electricity?\n",
      "9890:\tIn our village kachipul,flood caused huge loss.We lost Our crops,our houses and our jobs and every thing.But the government has not provided any sort of help for us so far\n",
      "3901:\tI thought the aftershocks were over. It seems that they are still producing. Can they alert us on that please. \n",
      "\n",
      "\n",
      "\n",
      "buildings (380) \n",
      "----\n",
      "9003:\tgood afternoon, can we get into our house if it's not cracked? \n",
      "3220:\tIf a house is not cracked can we go inside it? \n",
      "4862:\tI need food, I am in Gonaives, I came from PAP, my house was destroyed. Please call me at this number \n",
      "4894:\tI AM IN MISERY MY HOUSE IS BROCKEN ,I FOUND NOTHING TO EAT,PLEASE HELP ME \n",
      "126:\tI am from Anse a pitree my house which was in Delmas 32 was destroyed with everything I had inside. I went back to my hometown of Anse a pitrea. I would like to know how to get some help, because I have absolutely nothing!\n",
      "\n",
      "\n",
      "\n",
      "electricity (66) \n",
      "----\n",
      "2627:\thelp : water, food, way to have ( electricity )\n",
      "3323:\tI thought it was possible help would come from the forreigners here. Leogane, route .. \n",
      "8198:\tDo each haitian make money less than the money hi can eat each day, it's not a help but it's a way to continue with operating system. \n",
      "4561:\tWe are asking the ministry of public health to please help with the flies and mosquitoes that are in the shelters. Especially in Canape Vert \n",
      "4761:\tYou need to give electricity in Petion-ville now. \n",
      "\n",
      "\n",
      "\n",
      "tools (28) \n",
      "----\n",
      "3936:\tDiapers, etc. Have big truck huge to store goods f/distribution and security. Rte Clercine, Butte Boyer, (apres hotel Stephia Hotel), Impasse Gelin #2, \n",
      "9344:\tGreat I am nesly please tell me whether it is true that a volcano in Saut-d'Eau, and I want to know whether the election is effectively true, if yes when he is doing \n",
      "2580:\tweneed help in Ravine Pintade, right across from Olympic market\n",
      "2379:\tI would like to know what is happening in the country\n",
      "773:\ti have a problem talking to people in port au prince, please its talking to people god bless us\n",
      "\n",
      "\n",
      "\n",
      "hospitals (53) \n",
      "----\n",
      "9053:\twhat hospital is on for someone Emens tonight. \n",
      "3791:\tWhere can I find a health center in La Plaine \n",
      "3144:\tThe Doctors without Borders Hospital in Delmas 19 is closed. The Saint Louis Gonzaga hospital in Delmas 33 is taken in sick and wounded people for free \n",
      "6762:\tthe United Nation don't do nothing in Haiti \n",
      "2104:\tPlease, help me. I need clothes or anything.\n",
      "\n",
      "\n",
      "\n",
      "shops (31) \n",
      "----\n",
      "4862:\tI need food, I am in Gonaives, I came from PAP, my house was destroyed. Please call me at this number \n",
      "5417:\tPeople at Port Jeremie need tents and all other possible kinds of equipment. \n",
      "168:\tOne thing I am asking the money tranfer offices is for them to open so we can get the money sent to us.\n",
      "9903:\tIn our village Kachipur flood has done great damage. our crops, homes and business all have been destroyed. But the Government has not helped us till now. Location is Village Kachipul District Kambarshada\n",
      "2723:\ti am asking that the authorities help us. victims association christophe avenue fanfan impasse\n",
      "\n",
      "\n",
      "\n",
      "aid_centers (74) \n",
      "----\n",
      "8260:\tWill everybody find shelter ? Answer \n",
      "2835:\tEven that our father has died, we want to become professionals in all kind of fields of study. Help us find adequate shelter in other for the children to go to school. Best regards and may God bless you.\n",
      "4938:\tPlease, I would like to know what precautions there are for me to prevent all diseases from the catastrophe on January 12. \n",
      "2256:\tCit Militaire, we need water / food\n",
      "1758:\twill there be another earthquake this afternoon?\n",
      "\n",
      "\n",
      "\n",
      "other_infrastructure (178) \n",
      "----\n",
      "4667:\tI live in Carrefour-Feuilles, on Rue Sicot. I don't have shelter, food or water. \n",
      "823:\tI salute all those that are in charge at Digicel. In the name of God, I am a client of Digicel who is a victim of the earthquake that happened on January 12. I have problem. My house is cracked. I would like to go to Jeremie. Notes No name or location given.\n",
      "9906:\tWe are 17 people. Our house has been immersed(/flooded/inundated completely) and all property and livestock has been washed away by the flood. And our house was in Kachi. I am telling the truth. Thank you.\n",
      "1511:\tI need help my house collapsed and I'm in the streets\n",
      "170:\tGood morning, to everyone that is listening in Miami and other countries helping. I have my wife and five kids that will starve to death in Haiti if they do not get help. PLease help them! God will bless you!\n",
      "\n",
      "\n",
      "\n",
      "weather_related (1444) \n",
      "----\n",
      "8033:\tEarthquake in venezuela of 8.2, tsunami alert for the following island : Dominican republic, Haiti, Puerto rico, Jamaica, Trinidad and tobago, and virgin \n",
      "5060:\tNews regarding the Earthquake in Haiti \n",
      "81:\tA cold front is found over Cuba this morning. It could cross Haiti tomorrow. Isolated rain showers are expected over our region tonight.\n",
      "7072:\tPlease, give me some informations about the cyclon. \n",
      "3326:\tI need clothes, shoes, food. Right now. Ansdeno grandoie \n",
      "\n",
      "\n",
      "\n",
      "floods (282) \n",
      "----\n",
      "10093:\tSir, I request we KRT AP AP K K Kon kro justice of the United Nations have a right to the national highway Kon, Agr Han AP waqe Effecte flood affected people are madad KRT\n",
      "3401:\tNOTES: Statement. No emergency.\n",
      "1300:\tHello I'd like to know if really there will be more earthquakes again this weekend \n",
      "782:\tI live in Gonaives. I need help for the hospital in Raboto. We need water, food, and medication because we have a thousand people who need medical attention right now.\n",
      "9966:\twe are 100 flood effected .are we not register as a Pakistani nationality?we are requesting for you for the help. please do help us something location VILLAG CITY KACHIPUL Dist!Kamber Shahdad kot Taluka Qubo plz Vist Kachipul city\n",
      "\n",
      "\n",
      "\n",
      "storm (275) \n",
      "----\n",
      "81:\tA cold front is found over Cuba this morning. It could cross Haiti tomorrow. Isolated rain showers are expected over our region tonight.\n",
      "7685:\tGood evening, can I t o have the name of evey cyclones of this season,please? \n",
      "4436:\twe do not understand why we cant get a tent for kids that are 5 and 4 months old...last night it was raining on the kids \n",
      "6863:\tinformation about the hurrcane please. Thank you \n",
      "9237:\tThey say there is a hurrican ,would it be stared by rain. \n",
      "\n",
      "\n",
      "\n",
      "fire (38) \n",
      "----\n",
      "108:\tWe have a factory that is on FIRE on road to the airport near Sogebank. It's starting to burn several nearby houses with documents left in them. Please come and help us!!!\n",
      "3425:\tWhat should one do if they have a lot of bumps/pimples that are growing? \n",
      "4439:\twe are a group of women in twitye in carrefour. we would like to know where we can get coupons or cards to receive food \n",
      "3950:\tthe hospital sans frontiere need blood for those who still live,we need care now otherwise we die \n",
      "773:\ti have a problem talking to people in port au prince, please its talking to people god bless us\n",
      "\n",
      "\n",
      "\n",
      "earthquake (789) \n",
      "----\n",
      "9082:\twhat informations at the level of sismic plan in Haiti? \n",
      "3165:\tInformation on the earthquake. \n",
      "9194:\tIs it true from 17 through April 23 earthquake is more than strong? answer please. \n",
      "4578:\tWe are in Fontamara. We HAVE NOT RECEIVED ANYTHING SINCE the earthquake. \n",
      "1863:\twhen will this end, is it possible that there will be another earthquake in Port au Prince?\n",
      "\n",
      "\n",
      "\n",
      "cold (59) \n",
      "----\n",
      "2064:\tWe need potable water, food, many tents or the cold will kill us, medecine for flu, infection and fever etc. We have many children with us. We. .. \n",
      "81:\tA cold front is found over Cuba this morning. It could cross Haiti tomorrow. Isolated rain showers are expected over our region tonight.\n",
      "2980:\tFood is needed in Tabarre 43, Tapage Street, Paul Emile Street, Rapha Street and Rabbi Street..\n",
      "4568:\tA cold front was found in Cuba this morning. It is coming to Haiti tomorrow. Looks like there will be another round of rain showers this evening. \n",
      "2580:\tweneed help in Ravine Pintade, right across from Olympic market\n",
      "\n",
      "\n",
      "\n",
      "other_weather (194) \n",
      "----\n",
      "4111:\tStill in the area Fort Jack, route Kalbas. We have yet to find food along with the fact that there are people who need tents/place to stay because their houses fell. Give them a card \n",
      "2838:\tHello, please can you help me? I have someone who is under debris since 15 days ago. It's at the Canape Vert school. He had gone to learn about the part of education. ..\n",
      "934:\tHello, we are in the Petionville area we need tents, food and water\n",
      "2636:\tDelma 24, impass madiou, we need water and food they have not deliver any help for us\n",
      "259:\taid should reach the victims outside the city of p-au-p. we are in Gonaives when u get this message\n",
      "\n",
      "\n",
      "\n",
      "direct_report (3467) \n",
      "----\n",
      "8253:\twhen the ambushes of this century, hold closes even when life puts you in discomfiture, hold closes even that one of condescends your family, so God will facilitate you shortcoming \n",
      "9037:\turgent information: i responsible of a center name Oris Remy. im living in Leogane, chatile area. we found nothing since the earthquake, im asking for help. \n",
      "3129:\tIn Jacmel the aid is poorly organized. They only go to one place, Park Pinchinat, they don't come by to see the rest of the people who are left. It's only the rastas and the strongmen who get aid.. \n",
      "9146:\tinformations on the next earthquake \n",
      "2808:\twe need help in the town of ( bas Saintard, guitton, jean hose, mahotte ) in Arcahaie. A lot of people migrating from the capital. We need food,\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    category_rows_mask = df[label] == 1\n",
    "    category_df = df[category_rows_mask]\n",
    "    \n",
    "    category_size = category_df.shape[0]\n",
    "    \n",
    "    if category_size > 0:\n",
    "        \n",
    "        sample_size = 5\n",
    "        if category_size < 20:\n",
    "            sample_size = int(category_size / 4)\n",
    "            if sample_size < 1:\n",
    "                sample_size = 1\n",
    "\n",
    "        print(\"{} ({}) \\n----\".format(label, category_size))\n",
    "\n",
    "        sample = category_df['message'].sample(sample_size)\n",
    "        \n",
    "        for index, text in sample.iteritems():\n",
    "            print(\"{}:\\t{}\".format(index, text))\n",
    "              \n",
    "        print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
